Using loss: l2.
Using temporary directory /var/folders/9b/_dhnw9_17kgb24l4cq75nq9h0000gn/T/tmp_i8nweih.
gefundener dataset Path: /Users/wiebkezink/Documents/Uni Münster/MA/dataset
Dataset /dataset is copyable: False.
Loading /dataset dataset from /Users/wiebkezink/Documents/Uni Münster/MA/dataset.
Computed weighting 10.0-quantile-lower bound: 0.6454545454545455.
Length of train and val splits: 5, 3.
New length of train and val splits: 5, 3.
Using 0 workers.
Loading model - reinit: True | path: None specified.
Using architecture unet.
  2%|██▎                                                                                                                  | 2/100 [00:26<21:47, 13.34s/it]
Removed temporary directory /var/folders/9b/_dhnw9_17kgb24l4cq75nq9h0000gn/T/tmp_i8nweih.
Traceback (most recent call last):
  File "/Users/wiebkezink/Documents/Uni Münster/MA/Canopy-Height-Prediction/training/main.py", line 109, in <module>
    runner.run()
  File "/Users/wiebkezink/Documents/Uni Münster/MA/Canopy-Height-Prediction/training/runner.py", line 699, in run
    self.train()  # Train the model
  File "/Users/wiebkezink/Documents/Uni Münster/MA/Canopy-Height-Prediction/training/runner.py", line 636, in train
    ampGradScaler.scale(loss).backward()  # Scaling + Backpropagation
  File "/Users/wiebkezink/Documents/Uni Münster/MA/Canopy-Height-Prediction/venv/lib/python3.9/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/Users/wiebkezink/Documents/Uni Münster/MA/Canopy-Height-Prediction/venv/lib/python3.9/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/Users/wiebkezink/Documents/Uni Münster/MA/Canopy-Height-Prediction/venv/lib/python3.9/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
